# -*- coding: utf-8 -*-
"""backend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ypTfMo6lSvswHlOEM9_-6qlEc2GquuMX
"""

#set to GPU first!

!pip install -U accelerate bitsandbytes transformers huggingface_hub

!huggingface-cli login
#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

# Import necessary classes for model loading and quantization
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

# Configure model quantization to 4-bit for memory and computation efficiency
quantization_config = BitsAndBytesConfig(load_in_4bit=True)
#configure quantization by setting load_in_4bit=True, indicating that the model's
#weights should be pushed in 4-bit precision instead of the original 32-bit.
#This reduces memory consumption and potentially speeds up computations, making the
#model more efficient for resource-constrained environments.


# Load the tokenizer for the Gemma 7B Italian model
tokenizer = AutoTokenizer.from_pretrained("google/gemma-7b-it")
#load the pre-trained tokenizer specifically designed for the “google/gemma-7b-it”
#model using AutoTokenizer.from_pretrained(“google/gemma-7b-it”).


# Load the Gemma 7B Italian model itself, with 4-bit quantization
model = AutoModelForCausalLM.from_pretrained("google/gemma-7b-it",
                                             quantization_config=quantization_config)
#load the actual “google/gemma-7b-it” model, but with the crucial addition
#of the quantization configuration, ensuring that the model weights are created in the 4-bit format.


#Gemma Large Language Model is downloaded, converted into a 4-bit quantized model, and loaded into the GPU.

#start by setting the prompt
input_text = "who is joe"

# Now lets Tokenize the input text
input_ids = tokenizer(input_text, return_tensors="pt").to("cuda")

#call the model's generate function with the tokenized input and set a maximum output length of 512 tokens.
#This tells the model to generate text based on the given prompt while respecting the length limit.
outputs = model.generate(
    **input_ids,  # Pass tokenized input as keyword argument
    max_length=512,  # Limit output length to 512 tokens
)

# The generated text, represented as a sequence of token IDs, is decoded back into human-readable text using the tokenizer.decode function.
print(tokenizer.decode(outputs[0]))

"""###Fine Tuning Gemma to reflect our datasets!"""

!pip3 install -q -U datasets
!pip3 install -q -U pyarrow==15.0.0
!pip install --upgrade pyarrow

from datasets import load_dataset
from transformers import BitsAndBytesConfig, GemmaTokenizer
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(model, token=os.environ['HF_TOKEN'])
model = AutoModelForCausalLM.from_pretrained(model,
                                             quantization_config=bnb_config,
                                             device_map={"":0},
                                             token=os.environ['HF_TOKEN'])

data = load_dataset("training data set")
data = data.map(lambda samples: tokenizer(samples["item"]), batched=True)

xml_urls = [
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0034',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_M31201',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K319005',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_Z0252',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I14033',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I14034',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I742126',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K137087',

    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I739105',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I751501',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K116500',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K338002',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K090504',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_R0063',

    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_J64001',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_J64750',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K112149',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K116201',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K125100',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K131017',

    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K2638560',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K1096002',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K1949100',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K792001',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K165002',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_J63003',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0072',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0073',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0074',

    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0010',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0012',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0013',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0015',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0017',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0053',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0055',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B1002',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B1003',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B1004',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B1005',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B1006',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B1010',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I11013',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_I51003',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_J61048',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K1392970',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K1486001',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K1486005',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K1486009',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K780000',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K864501',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K864600',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K864601',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0011',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0014',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0021',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0024',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0050',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_B0051',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K2637012',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K2637014',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_K2637017',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',

    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    'https://parts.igem.org/cgi/xml/part.cgi?part=BBa_',
    # ... more URLs
]

#make a dataframe out of URLs
import requests
import xml.etree.ElementTree as ET

data = []

for url in xml_urls:
    response = requests.get(url)
    if response.status_code == 200:
        xml_content = response.text
        root = ET.fromstring(xml_content)
        #extract data from XML and append it to the 'data' list
        for item in root.findall('.//part'):
            data.append({
                'type': item.find('part_type').text,
                'name': item.find('part_name').text,
                'results': item.find('part_results').text,
                'description': item.find('part_short_desc').text,
                })
            subpart = item.find('.//sequences')
            if subpart is not None:
                # Similarly, find 'seq_data' directly under 'sequences'
                for sequence in subpart.findall('./seq_data'):
                    data.append({"sequence": sequence.text})
            subpart = item.find('.//categories')
            if subpart is not None:
                category_texts = [category.text for category in subpart.findall('.//category')]
                combined_category_text = " ".join(category_texts)
                data.append({"category": combined_category_text})
    else:
        print(f"Failed to fetch XML data from {url}")

print(data)

import pandas as pd

df = pd.DataFrame(data)

# Forward fill missing values
df_filled = df.fillna(method='ffill')

df_unique = df_filled.drop_duplicates(subset=['type', 'name'])
print(df_unique)

#export to CSV
df_unique.to_csv('igem_parts3.csv', index=False)  #index=False to avoid saving row numbers

import xml.etree.ElementTree as etree

# parse the XML content
root = etree.fromstring(xml_content)
for element in root:
    # access element tag, attributes, and text content
    print(element.tag, element.attrib, element.text)

"""###UI Design for software"""

!pip install streamlit

import streamlit as st
import pandas as pd

st.write("""
# My first app
Hello *world!*
""")

df = pd.read_csv("igem_parts3.csv")
st.line_chart(df)

class practice(App):
    def build(self):
        return practice()